¬°Claro! Aqu√≠ tienes un borrador de README.md detallado y con un toque visual para tu proyecto de GitHub.

```markdown
# üèùÔ∏è Chatbot para el Cabildo de Lanzarote  Lanzarote üáÆüá®

Este proyecto implementa un chatbot conversacional dise√±ado para proporcionar informaci√≥n relevante sobre el Cabildo de Lanzarote. Utiliza t√©cnicas de Web Scraping para recolectar datos, un modelo de lenguaje grande (LLM) para la comprensi√≥n y generaci√≥n de respuestas, y la plataforma AnythingLLM para la gesti√≥n y despliegue del chatbot.

## ü§ñ ¬øQu√© es un Chatbot?

Un chatbot es un programa inform√°tico dise√±ado para simular una conversaci√≥n humana a trav√©s de texto o voz. En este caso, nuestro chatbot est√° especializado en responder preguntas sobre los servicios, noticias, eventos y cualquier informaci√≥n p√∫blica relacionada con el Cabildo de Lanzarote, utilizando la informaci√≥n extra√≠da de su sitio web oficial.

## ‚ú® Caracter√≠sticas Principales

*   **Recolecci√≥n de Datos Automatizada:** Utiliza un script de Web Scraping para obtener informaci√≥n actualizada del sitio web del Cabildo.
*   **Procesamiento de Lenguaje Natural:** Emplea modelos LLM para entender las preguntas de los usuarios y generar respuestas coherentes.
*   **Base de Conocimiento Personalizada:** La informaci√≥n recolectada se utiliza para crear una base de conocimiento espec√≠fica para el chatbot.
*   **Interfaz de Usuario con AnythingLLM:** Se despliega y gestiona a trav√©s de AnythingLLM, permitiendo una f√°cil configuraci√≥n e interacci√≥n.
*   **Despliegue Local:** Utiliza Ollama para ejecutar modelos LLM localmente, asegurando la privacidad de los datos.

## üìö Tecnolog√≠as Utilizadas

*   **Python:** Para el Web Scraping y procesamiento de datos.
*   **Jupyter Notebook:** Para el an√°lisis y parsing de texto.
*   **Docker:** Para la contenerizaci√≥n y despliegue de AnythingLLM.
*   **AnythingLLM:** Plataforma para construir chatbots privados con LLMs.
*   **Ollama:** Para ejecutar modelos LLM (como Gemma y BGE-M3) localmente.

## üöÄ Pasos de Instalaci√≥n y Configuraci√≥n

Sigue estos pasos cuidadosamente para poner en marcha el chatbot:

---

### 1. Crear Entorno Virtual de Python e Instalar Dependencias

Es crucial aislar las dependencias del proyecto.

```bash
# Clona este repositorio (si a√∫n no lo has hecho)
# git clone <URL_DEL_REPOSITORIO>
# cd <NOMBRE_DEL_REPOSITORIO>

# Crea un entorno virtual
python -m venv env_chatbot_lanzarote

# Activa el entorno virtual
# En Windows:
env_chatbot_lanzarote\Scripts\activate
# En macOS/Linux:
source env_chatbot_lanzarote/bin/activate

# Instala las dependencias
pip install -r requirements.txt
```
> **Nota:** Aseg√∫rate de tener Python 3.8 o superior instalado.

---

### 2. Ejecutar el Web Scrapper

Este script recolectar√° la informaci√≥n necesaria del sitio web del Cabildo de Lanzarote.

```bash
python web_scrapper.py
```
> Este proceso puede tardar un tiempo dependiendo de la cantidad de informaci√≥n a extraer y la velocidad de tu conexi√≥n. Los datos se guardar√°n en archivos locales.

---

### 3. Ejecutar el Notebook `parser_str.ipynb`

Este notebook procesar√° y limpiar√° los datos recolectados por el scrapper, prepar√°ndolos para ser ingeridos por el LLM.

*   Abre Jupyter Notebook o Jupyter Lab.
*   Navega hasta el archivo `parser_str.ipynb` y ejec√∫talo celda por celda.
*   Esto generar√° los archivos de texto finales que se subir√°n a AnythingLLM.

---

### 4. Instalar Docker y Descargar la Imagen de AnythingLLM

Docker es necesario para ejecutar AnythingLLM en un contenedor.

*   **Instala Docker:** Si a√∫n no lo tienes, descarga e instala [Docker Desktop](https://www.docker.com/products/docker-desktop/) para tu sistema operativo.
*   **Descarga la imagen de AnythingLLM:**
    ```bash
    docker pull mintplexlabs/anythingllm:latest
    ```

---

### 5. Ejecutar el Contenedor de AnythingLLM

Elige el comando seg√∫n tu sistema operativo:

*   **Windows (usando PowerShell como Administrador):**
    ```powershell
      $env:STORAGE_LOCATION="$HOME\Documents\anythingllm"; `
      If(!(Test-Path $env:STORAGE_LOCATION)) {New-Item $env:STORAGE_LOCATION -ItemType Directory}; `
      If(!(Test-Path "$env:STORAGE_LOCATION\.env")) {New-Item "$env:STORAGE_LOCATION\.env" -ItemType File}; `
      docker run -d -p 3001:3001 `
      --cap-add SYS_ADMIN `
      -v "$env:STORAGE_LOCATION`:/app/server/storage" `
      -v "$env:STORAGE_LOCATION\.env:/app/server/.env" `
      -e STORAGE_DIR="/app/server/storage" `
      mintplexlabs/anythingllm;
    ```

*   **Linux o macOS (usando la terminal):**
    ```bash
      export STORAGE_LOCATION=$HOME/anythingllm && \
      mkdir -p $STORAGE_LOCATION && \
      touch "$STORAGE_LOCATION/.env" && \
      docker run -d -p 3001:3001 \
      --cap-add SYS_ADMIN \
      -v ${STORAGE_LOCATION}:/app/server/storage \
      -v ${STORAGE_LOCATION}/.env:/app/server/.env \
      -e STORAGE_DIR="/app/server/storage" \
      mintplexlabs/anythingllm
    ```
> Una vez ejecutado, podr√°s acceder a AnythingLLM desde tu navegador en `http://localhost:3001`.

---

### 6. Instalar Ollama y Descargar Modelos LLM

Ollama permite ejecutar modelos de lenguaje grandes localmente.

*   **Instala Ollama:** Visita [ollama.com](https://ollama.com/) y sigue las instrucciones de instalaci√≥n para tu sistema operativo.
*   **Descarga los modelos necesarios:**
    ```bash
    ollama pull gemma3:4b 
    ollama pull bge-m3
    ```
> **Importante:** Ejecutar modelos LLM localmente puede requerir una cantidad significativa de RAM y, preferiblemente, una GPU. `gemma:2b` es m√°s ligero, `gemma:7b` o `gemma3:4b` (si existe) necesitar√°n m√°s recursos.

---

### 7. Configurar AnythingLLM ‚öôÔ∏è

Accede a `http://localhost:3001` y sigue estos pasos para la configuraci√≥n inicial:

*   **a) Preferencia de LLM:**
    *   **LLM Provider:** `Ollama`
    *   **Ollama Base URL:** `http://host.docker.internal:11434`
        *   *Nota:* `host.docker.internal` es un DNS especial que Docker resuelve a la IP interna del host desde dentro de un contenedor. Si esto no funciona (por ejemplo, en Linux a veces requiere configuraci√≥n extra de Docker), puedes usar la IP de tu m√°quina en la red local (ej. `http://192.168.1.XX:11434`).
*   **b) Preferencia de LLM:**
    *   **Ollama Model Selection:**  `gemma3:4b` 
*   **c) Preferencia de Incrustaci√≥n (Embedding):**
    *   **Embedding Provider:** `Ollama`
*   **d) Preferencia de Incrustaci√≥n:**
    *   **Ollama Embedding Model Selection:** `bge-m3:latest`
*   **e) Preferencia de Incrustaci√≥n:**
    *   **Max Embedding Chunk Length:** `8192` (o el m√°ximo que permita `bge-m3`)
*   **f) Preferencias de Divisi√≥n y Fragmentaci√≥n de Texto:**
    *   **Text Chunk Size:** `8192` (ajusta seg√∫n el modelo y la naturaleza de tus datos, pero debe ser consistente con el Embedding Chunk Length)

---

### 8. Crear un Nuevo Espacio de Trabajo (Workspace) üìÇ

Dentro de AnythingLLM, crea un nuevo espacio de trabajo para el chatbot del Cabildo.

*   **Nombre del Workspace:** Algo descriptivo, ej. "Chatbot Cabildo Lanzarote"
*   **Configuraci√≥n del Chat:**
    *   **a) Modo de Chat:** `Consulta` (Query)
    *   **b) Historial de Chat:** `2` (N√∫mero de mensajes anteriores a considerar en la conversaci√≥n)
    *   **c) Prompt del Sistema (System Prompt):**
        ```text
        Eres un chatbot del cabildo de lanzarote, una pagina goburnamental. Dada la siguiente conversaci√≥n, el contexto (posiblemente relevante o no ) y una pregunta de seguimiento, responde a la pregunta actual que el usuario est√° haciendo. Devuelve √∫nicamente tu respuesta a la pregunta, bas√°ndote en la informaci√≥n anterior, siguiendo las instrucciones del usuario seg√∫n sea necesario y citando el enlace (url) fuente de la informaci√≥n. Tendr√°s que responder en el mismo idioma en el que se te pregunta. Responde √∫nicamente en base al contexto que se te pase. Devuelve la respuesta en Espa√±ol. Ten en cuenta que de los contexto pasados, puede estar bien solamente uno, y puede no ser el primero, o el segundo, o el tercero, etc.
        ```
*   **Base de Datos de Vectores (Vector Database):**
    *   **d) Search Preference:** `Accuracy optimized` (Optimizado para precisi√≥n)
    *   **e) M√°ximo de fragmentos de contexto:** `8`
    *   **f) Umbral de similitud de documentos:** `Bajo` (Low) - Esto permite recuperar m√°s documentos aunque no sean exactamente iguales. Puedes ajustarlo m√°s tarde.

---

### 9. Subir los Archivos de Texto Generados üìÑ

En el espacio de trabajo que acabas de crear en AnythingLLM:

*   Navega a la secci√≥n de gesti√≥n de documentos o "Upload Documents".
*   Sube los archivos `.txt` que fueron generados por el notebook `parser_str.ipynb` (del paso 3).
*   AnythingLLM procesar√° estos archivos y crear√° los embeddings. Este proceso puede tomar un tiempo.

---

### 10. Incrustar el Widget de Chat en una P√°gina Web üåê (Opcional)

Si deseas integrar el chatbot en una p√°gina web existente:

*   En la configuraci√≥n de AnythingLLM, busca la secci√≥n "Embeddable Chat Widgets" o similar.
*   Genera un nuevo widget de chat incrustable.
*   Copia el c√≥digo HTML/JavaScript proporcionado.
*   Pega este c√≥digo despues del `<body>` de la p√°gina web donde quieras que aparezca el chatbot.

---

## üéâ ¬°Listo para Chatear!

Una vez completados todos los pasos, deber√≠as poder interactuar con tu chatbot del Cabildo de Lanzarote a trav√©s de la interfaz de AnythingLLM o la p√°gina web donde lo hayas incrustado.

## ü§ù Contribuciones

Las contribuciones son bienvenidas. Si tienes ideas para mejorar el scrapper, el procesamiento de datos, los prompts o cualquier otro aspecto del proyecto, por favor abre un Pull Request o un Issue.

## üìú Licencia

(Especifica aqu√≠ la licencia de tu proyecto, ej. MIT, Apache 2.0, etc. Si no est√°s seguro, MIT es una opci√≥n com√∫n y permisiva).
```

### Consideraciones Adicionales:

1.  **`gemma3:4b`:** No estoy completamente seguro si `gemma3:4b` es un tag oficial y ampliamente disponible en Ollama. Si no lo es, el usuario deber√° ajustarlo al modelo `gemma` que mejor se adapte a sus recursos (e.g., `gemma:2b` o `gemma:7b`). He puesto `gemma:2b` como un ejemplo funcional y he a√±adido una nota al respecto. El usuario debe verificar los modelos disponibles con `ollama list`.
2.  **Claridad en PowerShell:** He mantenido el comando de PowerShell tal cual lo proporcionaste, asumiendo que es correcto.
3.  **Emojis y Formato:** He intentado a√±adir emojis y usar formato Markdown para hacerlo m√°s "bonito" y legible.
4.  **Comentarios en C√≥digo:** He a√±adido comentarios en los bloques de c√≥digo para mayor claridad.
5.  **Flujo L√≥gico:** Los pasos est√°n ordenados l√≥gicamente seg√∫n la descripci√≥n.

Espero que este README sea de tu agrado y √∫til para tu proyecto. ¬°Mucha suerte!
